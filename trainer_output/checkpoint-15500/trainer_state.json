{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1291.6666666666667,
  "eval_steps": 1000,
  "global_step": 15500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.6051833629608154,
      "learning_rate": 9.95875e-05,
      "loss": 2.8721,
      "step": 100
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.6891583800315857,
      "learning_rate": 9.917083333333333e-05,
      "loss": 2.8458,
      "step": 200
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.4945807456970215,
      "learning_rate": 9.875416666666667e-05,
      "loss": 2.8217,
      "step": 300
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 0.6994916796684265,
      "learning_rate": 9.83375e-05,
      "loss": 2.7959,
      "step": 400
    },
    {
      "epoch": 41.666666666666664,
      "grad_norm": 0.5926724076271057,
      "learning_rate": 9.792083333333334e-05,
      "loss": 2.7702,
      "step": 500
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.49113836884498596,
      "learning_rate": 9.750416666666668e-05,
      "loss": 2.7423,
      "step": 600
    },
    {
      "epoch": 58.333333333333336,
      "grad_norm": 0.6291890144348145,
      "learning_rate": 9.708750000000001e-05,
      "loss": 2.7142,
      "step": 700
    },
    {
      "epoch": 66.66666666666667,
      "grad_norm": 0.6625835299491882,
      "learning_rate": 9.667083333333334e-05,
      "loss": 2.6863,
      "step": 800
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.6799992918968201,
      "learning_rate": 9.625416666666666e-05,
      "loss": 2.6561,
      "step": 900
    },
    {
      "epoch": 83.33333333333333,
      "grad_norm": 0.5365527868270874,
      "learning_rate": 9.58375e-05,
      "loss": 2.6269,
      "step": 1000
    },
    {
      "epoch": 83.33333333333333,
      "eval_accuracy": 0.0,
      "eval_loss": 2.610473155975342,
      "eval_runtime": 0.0919,
      "eval_samples_per_second": 522.575,
      "eval_steps_per_second": 65.322,
      "step": 1000
    },
    {
      "epoch": 91.66666666666667,
      "grad_norm": 0.5170283913612366,
      "learning_rate": 9.542083333333333e-05,
      "loss": 2.5955,
      "step": 1100
    },
    {
      "epoch": 100.0,
      "grad_norm": 0.607541561126709,
      "learning_rate": 9.500416666666667e-05,
      "loss": 2.5644,
      "step": 1200
    },
    {
      "epoch": 108.33333333333333,
      "grad_norm": 0.5037108063697815,
      "learning_rate": 9.45875e-05,
      "loss": 2.5346,
      "step": 1300
    },
    {
      "epoch": 116.66666666666667,
      "grad_norm": 0.5894513130187988,
      "learning_rate": 9.417083333333334e-05,
      "loss": 2.5056,
      "step": 1400
    },
    {
      "epoch": 125.0,
      "grad_norm": 0.6103312373161316,
      "learning_rate": 9.375416666666667e-05,
      "loss": 2.4775,
      "step": 1500
    },
    {
      "epoch": 133.33333333333334,
      "grad_norm": 0.6311905384063721,
      "learning_rate": 9.33375e-05,
      "loss": 2.4463,
      "step": 1600
    },
    {
      "epoch": 141.66666666666666,
      "grad_norm": 0.49509310722351074,
      "learning_rate": 9.292083333333334e-05,
      "loss": 2.427,
      "step": 1700
    },
    {
      "epoch": 150.0,
      "grad_norm": 0.630032479763031,
      "learning_rate": 9.250416666666667e-05,
      "loss": 2.3949,
      "step": 1800
    },
    {
      "epoch": 158.33333333333334,
      "grad_norm": 0.8644905090332031,
      "learning_rate": 9.208750000000001e-05,
      "loss": 2.3709,
      "step": 1900
    },
    {
      "epoch": 166.66666666666666,
      "grad_norm": 0.5915117859840393,
      "learning_rate": 9.167083333333334e-05,
      "loss": 2.3518,
      "step": 2000
    },
    {
      "epoch": 166.66666666666666,
      "eval_accuracy": 0.0,
      "eval_loss": 2.336409091949463,
      "eval_runtime": 0.0367,
      "eval_samples_per_second": 1306.798,
      "eval_steps_per_second": 163.35,
      "step": 2000
    },
    {
      "epoch": 175.0,
      "grad_norm": 0.8363578915596008,
      "learning_rate": 9.125416666666668e-05,
      "loss": 2.323,
      "step": 2100
    },
    {
      "epoch": 183.33333333333334,
      "grad_norm": 0.6104052662849426,
      "learning_rate": 9.08375e-05,
      "loss": 2.3039,
      "step": 2200
    },
    {
      "epoch": 191.66666666666666,
      "grad_norm": 0.8765939474105835,
      "learning_rate": 9.042083333333333e-05,
      "loss": 2.2825,
      "step": 2300
    },
    {
      "epoch": 200.0,
      "grad_norm": 0.5937686562538147,
      "learning_rate": 9.000416666666666e-05,
      "loss": 2.2597,
      "step": 2400
    },
    {
      "epoch": 208.33333333333334,
      "grad_norm": 0.6040323376655579,
      "learning_rate": 8.95875e-05,
      "loss": 2.2385,
      "step": 2500
    },
    {
      "epoch": 216.66666666666666,
      "grad_norm": 0.5004381537437439,
      "learning_rate": 8.917083333333333e-05,
      "loss": 2.2237,
      "step": 2600
    },
    {
      "epoch": 225.0,
      "grad_norm": 0.618463397026062,
      "learning_rate": 8.875416666666667e-05,
      "loss": 2.1976,
      "step": 2700
    },
    {
      "epoch": 233.33333333333334,
      "grad_norm": 0.5340010523796082,
      "learning_rate": 8.833750000000001e-05,
      "loss": 2.1759,
      "step": 2800
    },
    {
      "epoch": 241.66666666666666,
      "grad_norm": 0.5909866690635681,
      "learning_rate": 8.792083333333334e-05,
      "loss": 2.1618,
      "step": 2900
    },
    {
      "epoch": 250.0,
      "grad_norm": 0.6899327635765076,
      "learning_rate": 8.750416666666668e-05,
      "loss": 2.1411,
      "step": 3000
    },
    {
      "epoch": 250.0,
      "eval_accuracy": 0.0,
      "eval_loss": 2.1294522285461426,
      "eval_runtime": 0.0324,
      "eval_samples_per_second": 1481.89,
      "eval_steps_per_second": 185.236,
      "step": 3000
    },
    {
      "epoch": 258.3333333333333,
      "grad_norm": 0.4687138795852661,
      "learning_rate": 8.70875e-05,
      "loss": 2.1207,
      "step": 3100
    },
    {
      "epoch": 266.6666666666667,
      "grad_norm": 0.5910725593566895,
      "learning_rate": 8.667083333333334e-05,
      "loss": 2.0999,
      "step": 3200
    },
    {
      "epoch": 275.0,
      "grad_norm": 0.5603066682815552,
      "learning_rate": 8.625416666666666e-05,
      "loss": 2.0788,
      "step": 3300
    },
    {
      "epoch": 283.3333333333333,
      "grad_norm": 0.5540595650672913,
      "learning_rate": 8.58375e-05,
      "loss": 2.059,
      "step": 3400
    },
    {
      "epoch": 291.6666666666667,
      "grad_norm": 0.7471890449523926,
      "learning_rate": 8.542083333333333e-05,
      "loss": 2.043,
      "step": 3500
    },
    {
      "epoch": 300.0,
      "grad_norm": 0.4783265292644501,
      "learning_rate": 8.500416666666668e-05,
      "loss": 2.018,
      "step": 3600
    },
    {
      "epoch": 308.3333333333333,
      "grad_norm": 0.6339196562767029,
      "learning_rate": 8.45875e-05,
      "loss": 1.9961,
      "step": 3700
    },
    {
      "epoch": 316.6666666666667,
      "grad_norm": 0.731274425983429,
      "learning_rate": 8.417083333333333e-05,
      "loss": 1.9836,
      "step": 3800
    },
    {
      "epoch": 325.0,
      "grad_norm": 0.5988661646842957,
      "learning_rate": 8.375416666666667e-05,
      "loss": 1.9617,
      "step": 3900
    },
    {
      "epoch": 333.3333333333333,
      "grad_norm": 0.5876109600067139,
      "learning_rate": 8.33375e-05,
      "loss": 1.9412,
      "step": 4000
    },
    {
      "epoch": 333.3333333333333,
      "eval_accuracy": 0.0,
      "eval_loss": 1.9312082529067993,
      "eval_runtime": 0.029,
      "eval_samples_per_second": 1654.028,
      "eval_steps_per_second": 206.753,
      "step": 4000
    },
    {
      "epoch": 341.6666666666667,
      "grad_norm": 0.6149473786354065,
      "learning_rate": 8.292083333333334e-05,
      "loss": 1.9188,
      "step": 4100
    },
    {
      "epoch": 350.0,
      "grad_norm": 0.8243629336357117,
      "learning_rate": 8.250416666666667e-05,
      "loss": 1.9055,
      "step": 4200
    },
    {
      "epoch": 358.3333333333333,
      "grad_norm": 0.46535998582839966,
      "learning_rate": 8.208750000000001e-05,
      "loss": 1.882,
      "step": 4300
    },
    {
      "epoch": 366.6666666666667,
      "grad_norm": 0.5946319699287415,
      "learning_rate": 8.167083333333334e-05,
      "loss": 1.8675,
      "step": 4400
    },
    {
      "epoch": 375.0,
      "grad_norm": 0.6925668716430664,
      "learning_rate": 8.125416666666668e-05,
      "loss": 1.8444,
      "step": 4500
    },
    {
      "epoch": 383.3333333333333,
      "grad_norm": 0.5884158611297607,
      "learning_rate": 8.083749999999999e-05,
      "loss": 1.8229,
      "step": 4600
    },
    {
      "epoch": 391.6666666666667,
      "grad_norm": 0.6214852929115295,
      "learning_rate": 8.042083333333333e-05,
      "loss": 1.8121,
      "step": 4700
    },
    {
      "epoch": 400.0,
      "grad_norm": 0.6849515438079834,
      "learning_rate": 8.000416666666668e-05,
      "loss": 1.7932,
      "step": 4800
    },
    {
      "epoch": 408.3333333333333,
      "grad_norm": 0.692306399345398,
      "learning_rate": 7.95875e-05,
      "loss": 1.7752,
      "step": 4900
    },
    {
      "epoch": 416.6666666666667,
      "grad_norm": 0.47051310539245605,
      "learning_rate": 7.917083333333334e-05,
      "loss": 1.7551,
      "step": 5000
    },
    {
      "epoch": 416.6666666666667,
      "eval_accuracy": 0.1111111111111111,
      "eval_loss": 1.7475229501724243,
      "eval_runtime": 0.0313,
      "eval_samples_per_second": 1533.123,
      "eval_steps_per_second": 191.64,
      "step": 5000
    },
    {
      "epoch": 425.0,
      "grad_norm": 0.6122304201126099,
      "learning_rate": 7.875416666666667e-05,
      "loss": 1.739,
      "step": 5100
    },
    {
      "epoch": 433.3333333333333,
      "grad_norm": 0.7957572340965271,
      "learning_rate": 7.833750000000001e-05,
      "loss": 1.7236,
      "step": 5200
    },
    {
      "epoch": 441.6666666666667,
      "grad_norm": 0.5877705812454224,
      "learning_rate": 7.792083333333333e-05,
      "loss": 1.7054,
      "step": 5300
    },
    {
      "epoch": 450.0,
      "grad_norm": 0.6815887093544006,
      "learning_rate": 7.750416666666667e-05,
      "loss": 1.6893,
      "step": 5400
    },
    {
      "epoch": 458.3333333333333,
      "grad_norm": 0.7172768712043762,
      "learning_rate": 7.70875e-05,
      "loss": 1.676,
      "step": 5500
    },
    {
      "epoch": 466.6666666666667,
      "grad_norm": 0.5959444046020508,
      "learning_rate": 7.667083333333334e-05,
      "loss": 1.6566,
      "step": 5600
    },
    {
      "epoch": 475.0,
      "grad_norm": 0.5832722783088684,
      "learning_rate": 7.625416666666667e-05,
      "loss": 1.6433,
      "step": 5700
    },
    {
      "epoch": 483.3333333333333,
      "grad_norm": 0.6831578016281128,
      "learning_rate": 7.583750000000001e-05,
      "loss": 1.6307,
      "step": 5800
    },
    {
      "epoch": 491.6666666666667,
      "grad_norm": 0.6705030798912048,
      "learning_rate": 7.542083333333333e-05,
      "loss": 1.6148,
      "step": 5900
    },
    {
      "epoch": 500.0,
      "grad_norm": 0.5235075354576111,
      "learning_rate": 7.500416666666668e-05,
      "loss": 1.5967,
      "step": 6000
    },
    {
      "epoch": 500.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.592652440071106,
      "eval_runtime": 0.0337,
      "eval_samples_per_second": 1424.796,
      "eval_steps_per_second": 178.1,
      "step": 6000
    },
    {
      "epoch": 508.3333333333333,
      "grad_norm": 0.5465296506881714,
      "learning_rate": 7.45875e-05,
      "loss": 1.5861,
      "step": 6100
    },
    {
      "epoch": 516.6666666666666,
      "grad_norm": 0.5000943541526794,
      "learning_rate": 7.417083333333333e-05,
      "loss": 1.5752,
      "step": 6200
    },
    {
      "epoch": 525.0,
      "grad_norm": 0.651474118232727,
      "learning_rate": 7.375416666666667e-05,
      "loss": 1.5564,
      "step": 6300
    },
    {
      "epoch": 533.3333333333334,
      "grad_norm": 0.6664116382598877,
      "learning_rate": 7.33375e-05,
      "loss": 1.55,
      "step": 6400
    },
    {
      "epoch": 541.6666666666666,
      "grad_norm": 0.5444555282592773,
      "learning_rate": 7.292083333333334e-05,
      "loss": 1.5297,
      "step": 6500
    },
    {
      "epoch": 550.0,
      "grad_norm": 0.5460193753242493,
      "learning_rate": 7.250416666666667e-05,
      "loss": 1.5223,
      "step": 6600
    },
    {
      "epoch": 558.3333333333334,
      "grad_norm": 0.6637958288192749,
      "learning_rate": 7.208750000000001e-05,
      "loss": 1.5113,
      "step": 6700
    },
    {
      "epoch": 566.6666666666666,
      "grad_norm": 0.6307076811790466,
      "learning_rate": 7.167083333333332e-05,
      "loss": 1.4984,
      "step": 6800
    },
    {
      "epoch": 575.0,
      "grad_norm": 0.6201691031455994,
      "learning_rate": 7.125416666666667e-05,
      "loss": 1.4856,
      "step": 6900
    },
    {
      "epoch": 583.3333333333334,
      "grad_norm": 0.7593543529510498,
      "learning_rate": 7.083750000000001e-05,
      "loss": 1.4751,
      "step": 7000
    },
    {
      "epoch": 583.3333333333334,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.4706863164901733,
      "eval_runtime": 0.031,
      "eval_samples_per_second": 1549.489,
      "eval_steps_per_second": 193.686,
      "step": 7000
    },
    {
      "epoch": 591.6666666666666,
      "grad_norm": 0.714863657951355,
      "learning_rate": 7.042083333333334e-05,
      "loss": 1.4675,
      "step": 7100
    },
    {
      "epoch": 600.0,
      "grad_norm": 0.5217944979667664,
      "learning_rate": 7.000416666666668e-05,
      "loss": 1.4545,
      "step": 7200
    },
    {
      "epoch": 608.3333333333334,
      "grad_norm": 0.5966652035713196,
      "learning_rate": 6.95875e-05,
      "loss": 1.4452,
      "step": 7300
    },
    {
      "epoch": 616.6666666666666,
      "grad_norm": 0.6549707055091858,
      "learning_rate": 6.917083333333335e-05,
      "loss": 1.4338,
      "step": 7400
    },
    {
      "epoch": 625.0,
      "grad_norm": 0.7121021747589111,
      "learning_rate": 6.875416666666667e-05,
      "loss": 1.428,
      "step": 7500
    },
    {
      "epoch": 633.3333333333334,
      "grad_norm": 0.6304645538330078,
      "learning_rate": 6.83375e-05,
      "loss": 1.4146,
      "step": 7600
    },
    {
      "epoch": 641.6666666666666,
      "grad_norm": 0.4589557945728302,
      "learning_rate": 6.792083333333333e-05,
      "loss": 1.4083,
      "step": 7700
    },
    {
      "epoch": 650.0,
      "grad_norm": 0.5165436267852783,
      "learning_rate": 6.750416666666667e-05,
      "loss": 1.4016,
      "step": 7800
    },
    {
      "epoch": 658.3333333333334,
      "grad_norm": 0.6436544060707092,
      "learning_rate": 6.70875e-05,
      "loss": 1.388,
      "step": 7900
    },
    {
      "epoch": 666.6666666666666,
      "grad_norm": 0.679676353931427,
      "learning_rate": 6.667083333333334e-05,
      "loss": 1.3854,
      "step": 8000
    },
    {
      "epoch": 666.6666666666666,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.3788806200027466,
      "eval_runtime": 0.0312,
      "eval_samples_per_second": 1536.481,
      "eval_steps_per_second": 192.06,
      "step": 8000
    },
    {
      "epoch": 675.0,
      "grad_norm": 0.5151451230049133,
      "learning_rate": 6.625416666666667e-05,
      "loss": 1.3759,
      "step": 8100
    },
    {
      "epoch": 683.3333333333334,
      "grad_norm": 0.5730345845222473,
      "learning_rate": 6.583750000000001e-05,
      "loss": 1.3689,
      "step": 8200
    },
    {
      "epoch": 691.6666666666666,
      "grad_norm": 0.7313722372055054,
      "learning_rate": 6.542083333333334e-05,
      "loss": 1.3613,
      "step": 8300
    },
    {
      "epoch": 700.0,
      "grad_norm": 0.48919039964675903,
      "learning_rate": 6.500416666666666e-05,
      "loss": 1.3504,
      "step": 8400
    },
    {
      "epoch": 708.3333333333334,
      "grad_norm": 0.5409805178642273,
      "learning_rate": 6.45875e-05,
      "loss": 1.3455,
      "step": 8500
    },
    {
      "epoch": 716.6666666666666,
      "grad_norm": 0.5303018689155579,
      "learning_rate": 6.417083333333333e-05,
      "loss": 1.3404,
      "step": 8600
    },
    {
      "epoch": 725.0,
      "grad_norm": 0.5314298272132874,
      "learning_rate": 6.375416666666667e-05,
      "loss": 1.332,
      "step": 8700
    },
    {
      "epoch": 733.3333333333334,
      "grad_norm": 0.5693715214729309,
      "learning_rate": 6.33375e-05,
      "loss": 1.3274,
      "step": 8800
    },
    {
      "epoch": 741.6666666666666,
      "grad_norm": 0.5135254859924316,
      "learning_rate": 6.292083333333334e-05,
      "loss": 1.3192,
      "step": 8900
    },
    {
      "epoch": 750.0,
      "grad_norm": 0.5605344176292419,
      "learning_rate": 6.250416666666667e-05,
      "loss": 1.3141,
      "step": 9000
    },
    {
      "epoch": 750.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.311171293258667,
      "eval_runtime": 0.0297,
      "eval_samples_per_second": 1617.406,
      "eval_steps_per_second": 202.176,
      "step": 9000
    },
    {
      "epoch": 758.3333333333334,
      "grad_norm": 0.925197422504425,
      "learning_rate": 6.20875e-05,
      "loss": 1.3097,
      "step": 9100
    },
    {
      "epoch": 766.6666666666666,
      "grad_norm": 0.48476675152778625,
      "learning_rate": 6.167083333333334e-05,
      "loss": 1.3001,
      "step": 9200
    },
    {
      "epoch": 775.0,
      "grad_norm": 0.532160758972168,
      "learning_rate": 6.125416666666667e-05,
      "loss": 1.2989,
      "step": 9300
    },
    {
      "epoch": 783.3333333333334,
      "grad_norm": 0.43017223477363586,
      "learning_rate": 6.08375e-05,
      "loss": 1.292,
      "step": 9400
    },
    {
      "epoch": 791.6666666666666,
      "grad_norm": 0.4551057517528534,
      "learning_rate": 6.0420833333333336e-05,
      "loss": 1.2875,
      "step": 9500
    },
    {
      "epoch": 800.0,
      "grad_norm": 0.5898595452308655,
      "learning_rate": 6.000416666666667e-05,
      "loss": 1.2817,
      "step": 9600
    },
    {
      "epoch": 808.3333333333334,
      "grad_norm": 0.6216546893119812,
      "learning_rate": 5.9587500000000005e-05,
      "loss": 1.2753,
      "step": 9700
    },
    {
      "epoch": 816.6666666666666,
      "grad_norm": 0.8155809044837952,
      "learning_rate": 5.917083333333333e-05,
      "loss": 1.2756,
      "step": 9800
    },
    {
      "epoch": 825.0,
      "grad_norm": 0.7431382536888123,
      "learning_rate": 5.875416666666667e-05,
      "loss": 1.2673,
      "step": 9900
    },
    {
      "epoch": 833.3333333333334,
      "grad_norm": 0.45613834261894226,
      "learning_rate": 5.83375e-05,
      "loss": 1.2626,
      "step": 10000
    },
    {
      "epoch": 833.3333333333334,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.2615894079208374,
      "eval_runtime": 0.0313,
      "eval_samples_per_second": 1532.131,
      "eval_steps_per_second": 191.516,
      "step": 10000
    },
    {
      "epoch": 841.6666666666666,
      "grad_norm": 0.7146485447883606,
      "learning_rate": 5.7920833333333336e-05,
      "loss": 1.262,
      "step": 10100
    },
    {
      "epoch": 850.0,
      "grad_norm": 0.5957129597663879,
      "learning_rate": 5.750416666666667e-05,
      "loss": 1.2543,
      "step": 10200
    },
    {
      "epoch": 858.3333333333334,
      "grad_norm": 0.5985375642776489,
      "learning_rate": 5.7087500000000005e-05,
      "loss": 1.2491,
      "step": 10300
    },
    {
      "epoch": 866.6666666666666,
      "grad_norm": 0.5014562606811523,
      "learning_rate": 5.667083333333334e-05,
      "loss": 1.2505,
      "step": 10400
    },
    {
      "epoch": 875.0,
      "grad_norm": 0.5237607359886169,
      "learning_rate": 5.6254166666666674e-05,
      "loss": 1.2436,
      "step": 10500
    },
    {
      "epoch": 883.3333333333334,
      "grad_norm": 0.665937602519989,
      "learning_rate": 5.5837499999999995e-05,
      "loss": 1.2391,
      "step": 10600
    },
    {
      "epoch": 891.6666666666666,
      "grad_norm": 0.6419817209243774,
      "learning_rate": 5.542083333333333e-05,
      "loss": 1.2414,
      "step": 10700
    },
    {
      "epoch": 900.0,
      "grad_norm": 0.5191245079040527,
      "learning_rate": 5.500416666666667e-05,
      "loss": 1.2299,
      "step": 10800
    },
    {
      "epoch": 908.3333333333334,
      "grad_norm": 0.7462837100028992,
      "learning_rate": 5.4587500000000005e-05,
      "loss": 1.2309,
      "step": 10900
    },
    {
      "epoch": 916.6666666666666,
      "grad_norm": 0.7026402354240417,
      "learning_rate": 5.417083333333334e-05,
      "loss": 1.224,
      "step": 11000
    },
    {
      "epoch": 916.6666666666666,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.2251195907592773,
      "eval_runtime": 0.03,
      "eval_samples_per_second": 1602.243,
      "eval_steps_per_second": 200.28,
      "step": 11000
    },
    {
      "epoch": 925.0,
      "grad_norm": 0.6570234894752502,
      "learning_rate": 5.3754166666666674e-05,
      "loss": 1.2256,
      "step": 11100
    },
    {
      "epoch": 933.3333333333334,
      "grad_norm": 0.7420072555541992,
      "learning_rate": 5.333750000000001e-05,
      "loss": 1.2272,
      "step": 11200
    },
    {
      "epoch": 941.6666666666666,
      "grad_norm": 0.5007108449935913,
      "learning_rate": 5.292083333333333e-05,
      "loss": 1.2105,
      "step": 11300
    },
    {
      "epoch": 950.0,
      "grad_norm": 0.6749826669692993,
      "learning_rate": 5.2504166666666664e-05,
      "loss": 1.2155,
      "step": 11400
    },
    {
      "epoch": 958.3333333333334,
      "grad_norm": 0.4446224570274353,
      "learning_rate": 5.20875e-05,
      "loss": 1.212,
      "step": 11500
    },
    {
      "epoch": 966.6666666666666,
      "grad_norm": 0.46584558486938477,
      "learning_rate": 5.1670833333333333e-05,
      "loss": 1.2097,
      "step": 11600
    },
    {
      "epoch": 975.0,
      "grad_norm": 0.4884452223777771,
      "learning_rate": 5.125416666666667e-05,
      "loss": 1.2067,
      "step": 11700
    },
    {
      "epoch": 983.3333333333334,
      "grad_norm": 0.6299191117286682,
      "learning_rate": 5.08375e-05,
      "loss": 1.2032,
      "step": 11800
    },
    {
      "epoch": 991.6666666666666,
      "grad_norm": 0.6531593799591064,
      "learning_rate": 5.042083333333334e-05,
      "loss": 1.2039,
      "step": 11900
    },
    {
      "epoch": 1000.0,
      "grad_norm": 0.43738189339637756,
      "learning_rate": 5.000416666666667e-05,
      "loss": 1.1985,
      "step": 12000
    },
    {
      "epoch": 1000.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.198221206665039,
      "eval_runtime": 0.0331,
      "eval_samples_per_second": 1450.992,
      "eval_steps_per_second": 181.374,
      "step": 12000
    },
    {
      "epoch": 1008.3333333333334,
      "grad_norm": 0.5184521675109863,
      "learning_rate": 4.9587500000000006e-05,
      "loss": 1.197,
      "step": 12100
    },
    {
      "epoch": 1016.6666666666666,
      "grad_norm": 0.5186393857002258,
      "learning_rate": 4.917083333333334e-05,
      "loss": 1.1946,
      "step": 12200
    },
    {
      "epoch": 1025.0,
      "grad_norm": 0.632483184337616,
      "learning_rate": 4.875416666666667e-05,
      "loss": 1.1932,
      "step": 12300
    },
    {
      "epoch": 1033.3333333333333,
      "grad_norm": 0.6350398063659668,
      "learning_rate": 4.83375e-05,
      "loss": 1.1912,
      "step": 12400
    },
    {
      "epoch": 1041.6666666666667,
      "grad_norm": 0.5078209638595581,
      "learning_rate": 4.792083333333334e-05,
      "loss": 1.1884,
      "step": 12500
    },
    {
      "epoch": 1050.0,
      "grad_norm": 0.6096820831298828,
      "learning_rate": 4.7504166666666665e-05,
      "loss": 1.186,
      "step": 12600
    },
    {
      "epoch": 1058.3333333333333,
      "grad_norm": 0.5128987431526184,
      "learning_rate": 4.70875e-05,
      "loss": 1.1888,
      "step": 12700
    },
    {
      "epoch": 1066.6666666666667,
      "grad_norm": 0.49676260352134705,
      "learning_rate": 4.6670833333333334e-05,
      "loss": 1.1794,
      "step": 12800
    },
    {
      "epoch": 1075.0,
      "grad_norm": 0.511321485042572,
      "learning_rate": 4.625416666666667e-05,
      "loss": 1.18,
      "step": 12900
    },
    {
      "epoch": 1083.3333333333333,
      "grad_norm": 0.6031290292739868,
      "learning_rate": 4.58375e-05,
      "loss": 1.1765,
      "step": 13000
    },
    {
      "epoch": 1083.3333333333333,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1781212091445923,
      "eval_runtime": 0.0324,
      "eval_samples_per_second": 1483.222,
      "eval_steps_per_second": 185.403,
      "step": 13000
    },
    {
      "epoch": 1091.6666666666667,
      "grad_norm": 0.5112612247467041,
      "learning_rate": 4.542083333333334e-05,
      "loss": 1.1786,
      "step": 13100
    },
    {
      "epoch": 1100.0,
      "grad_norm": 0.47424793243408203,
      "learning_rate": 4.500416666666667e-05,
      "loss": 1.177,
      "step": 13200
    },
    {
      "epoch": 1108.3333333333333,
      "grad_norm": 0.48695313930511475,
      "learning_rate": 4.4587500000000006e-05,
      "loss": 1.1716,
      "step": 13300
    },
    {
      "epoch": 1116.6666666666667,
      "grad_norm": 0.45062363147735596,
      "learning_rate": 4.4170833333333334e-05,
      "loss": 1.1749,
      "step": 13400
    },
    {
      "epoch": 1125.0,
      "grad_norm": 0.47126057744026184,
      "learning_rate": 4.375416666666667e-05,
      "loss": 1.1707,
      "step": 13500
    },
    {
      "epoch": 1133.3333333333333,
      "grad_norm": 0.4777139127254486,
      "learning_rate": 4.33375e-05,
      "loss": 1.168,
      "step": 13600
    },
    {
      "epoch": 1141.6666666666667,
      "grad_norm": 0.5064113736152649,
      "learning_rate": 4.292083333333334e-05,
      "loss": 1.1702,
      "step": 13700
    },
    {
      "epoch": 1150.0,
      "grad_norm": 0.6166946887969971,
      "learning_rate": 4.2504166666666665e-05,
      "loss": 1.1654,
      "step": 13800
    },
    {
      "epoch": 1158.3333333333333,
      "grad_norm": 0.494022935628891,
      "learning_rate": 4.20875e-05,
      "loss": 1.1641,
      "step": 13900
    },
    {
      "epoch": 1166.6666666666667,
      "grad_norm": 0.5007319450378418,
      "learning_rate": 4.1670833333333334e-05,
      "loss": 1.1632,
      "step": 14000
    },
    {
      "epoch": 1166.6666666666667,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1629260778427124,
      "eval_runtime": 0.0341,
      "eval_samples_per_second": 1407.76,
      "eval_steps_per_second": 175.97,
      "step": 14000
    },
    {
      "epoch": 1175.0,
      "grad_norm": 1.0092177391052246,
      "learning_rate": 4.125416666666667e-05,
      "loss": 1.1637,
      "step": 14100
    },
    {
      "epoch": 1183.3333333333333,
      "grad_norm": 0.5052011013031006,
      "learning_rate": 4.08375e-05,
      "loss": 1.1597,
      "step": 14200
    },
    {
      "epoch": 1191.6666666666667,
      "grad_norm": 0.47495245933532715,
      "learning_rate": 4.042083333333334e-05,
      "loss": 1.1614,
      "step": 14300
    },
    {
      "epoch": 1200.0,
      "grad_norm": 0.493790864944458,
      "learning_rate": 4.000416666666667e-05,
      "loss": 1.1583,
      "step": 14400
    },
    {
      "epoch": 1208.3333333333333,
      "grad_norm": 0.4815879166126251,
      "learning_rate": 3.95875e-05,
      "loss": 1.1584,
      "step": 14500
    },
    {
      "epoch": 1216.6666666666667,
      "grad_norm": 0.4668075442314148,
      "learning_rate": 3.9170833333333335e-05,
      "loss": 1.1544,
      "step": 14600
    },
    {
      "epoch": 1225.0,
      "grad_norm": 0.6175908446311951,
      "learning_rate": 3.875416666666667e-05,
      "loss": 1.156,
      "step": 14700
    },
    {
      "epoch": 1233.3333333333333,
      "grad_norm": 0.4562186598777771,
      "learning_rate": 3.8337500000000004e-05,
      "loss": 1.1541,
      "step": 14800
    },
    {
      "epoch": 1241.6666666666667,
      "grad_norm": 0.6359095573425293,
      "learning_rate": 3.792083333333333e-05,
      "loss": 1.1556,
      "step": 14900
    },
    {
      "epoch": 1250.0,
      "grad_norm": 0.6147501468658447,
      "learning_rate": 3.7504166666666666e-05,
      "loss": 1.1492,
      "step": 15000
    },
    {
      "epoch": 1250.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1513322591781616,
      "eval_runtime": 0.0354,
      "eval_samples_per_second": 1356.155,
      "eval_steps_per_second": 169.519,
      "step": 15000
    },
    {
      "epoch": 1258.3333333333333,
      "grad_norm": 0.4394721984863281,
      "learning_rate": 3.70875e-05,
      "loss": 1.1496,
      "step": 15100
    },
    {
      "epoch": 1266.6666666666667,
      "grad_norm": 0.48764464259147644,
      "learning_rate": 3.6670833333333335e-05,
      "loss": 1.1511,
      "step": 15200
    },
    {
      "epoch": 1275.0,
      "grad_norm": 0.5679791569709778,
      "learning_rate": 3.625416666666667e-05,
      "loss": 1.1491,
      "step": 15300
    },
    {
      "epoch": 1283.3333333333333,
      "grad_norm": 0.5071014165878296,
      "learning_rate": 3.5837500000000004e-05,
      "loss": 1.1463,
      "step": 15400
    },
    {
      "epoch": 1291.6666666666667,
      "grad_norm": 0.6192807555198669,
      "learning_rate": 3.542083333333334e-05,
      "loss": 1.1488,
      "step": 15500
    }
  ],
  "logging_steps": 100,
  "max_steps": 24000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2000,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
