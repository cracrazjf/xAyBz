{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1833.3333333333333,
  "eval_steps": 1000,
  "global_step": 22000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.6051833629608154,
      "learning_rate": 9.95875e-05,
      "loss": 2.8721,
      "step": 100
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.6891583800315857,
      "learning_rate": 9.917083333333333e-05,
      "loss": 2.8458,
      "step": 200
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.4945807456970215,
      "learning_rate": 9.875416666666667e-05,
      "loss": 2.8217,
      "step": 300
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 0.6994916796684265,
      "learning_rate": 9.83375e-05,
      "loss": 2.7959,
      "step": 400
    },
    {
      "epoch": 41.666666666666664,
      "grad_norm": 0.5926724076271057,
      "learning_rate": 9.792083333333334e-05,
      "loss": 2.7702,
      "step": 500
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.49113836884498596,
      "learning_rate": 9.750416666666668e-05,
      "loss": 2.7423,
      "step": 600
    },
    {
      "epoch": 58.333333333333336,
      "grad_norm": 0.6291890144348145,
      "learning_rate": 9.708750000000001e-05,
      "loss": 2.7142,
      "step": 700
    },
    {
      "epoch": 66.66666666666667,
      "grad_norm": 0.6625835299491882,
      "learning_rate": 9.667083333333334e-05,
      "loss": 2.6863,
      "step": 800
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.6799992918968201,
      "learning_rate": 9.625416666666666e-05,
      "loss": 2.6561,
      "step": 900
    },
    {
      "epoch": 83.33333333333333,
      "grad_norm": 0.5365527868270874,
      "learning_rate": 9.58375e-05,
      "loss": 2.6269,
      "step": 1000
    },
    {
      "epoch": 83.33333333333333,
      "eval_accuracy": 0.0,
      "eval_loss": 2.610473155975342,
      "eval_runtime": 0.0919,
      "eval_samples_per_second": 522.575,
      "eval_steps_per_second": 65.322,
      "step": 1000
    },
    {
      "epoch": 91.66666666666667,
      "grad_norm": 0.5170283913612366,
      "learning_rate": 9.542083333333333e-05,
      "loss": 2.5955,
      "step": 1100
    },
    {
      "epoch": 100.0,
      "grad_norm": 0.607541561126709,
      "learning_rate": 9.500416666666667e-05,
      "loss": 2.5644,
      "step": 1200
    },
    {
      "epoch": 108.33333333333333,
      "grad_norm": 0.5037108063697815,
      "learning_rate": 9.45875e-05,
      "loss": 2.5346,
      "step": 1300
    },
    {
      "epoch": 116.66666666666667,
      "grad_norm": 0.5894513130187988,
      "learning_rate": 9.417083333333334e-05,
      "loss": 2.5056,
      "step": 1400
    },
    {
      "epoch": 125.0,
      "grad_norm": 0.6103312373161316,
      "learning_rate": 9.375416666666667e-05,
      "loss": 2.4775,
      "step": 1500
    },
    {
      "epoch": 133.33333333333334,
      "grad_norm": 0.6311905384063721,
      "learning_rate": 9.33375e-05,
      "loss": 2.4463,
      "step": 1600
    },
    {
      "epoch": 141.66666666666666,
      "grad_norm": 0.49509310722351074,
      "learning_rate": 9.292083333333334e-05,
      "loss": 2.427,
      "step": 1700
    },
    {
      "epoch": 150.0,
      "grad_norm": 0.630032479763031,
      "learning_rate": 9.250416666666667e-05,
      "loss": 2.3949,
      "step": 1800
    },
    {
      "epoch": 158.33333333333334,
      "grad_norm": 0.8644905090332031,
      "learning_rate": 9.208750000000001e-05,
      "loss": 2.3709,
      "step": 1900
    },
    {
      "epoch": 166.66666666666666,
      "grad_norm": 0.5915117859840393,
      "learning_rate": 9.167083333333334e-05,
      "loss": 2.3518,
      "step": 2000
    },
    {
      "epoch": 166.66666666666666,
      "eval_accuracy": 0.0,
      "eval_loss": 2.336409091949463,
      "eval_runtime": 0.0367,
      "eval_samples_per_second": 1306.798,
      "eval_steps_per_second": 163.35,
      "step": 2000
    },
    {
      "epoch": 175.0,
      "grad_norm": 0.8363578915596008,
      "learning_rate": 9.125416666666668e-05,
      "loss": 2.323,
      "step": 2100
    },
    {
      "epoch": 183.33333333333334,
      "grad_norm": 0.6104052662849426,
      "learning_rate": 9.08375e-05,
      "loss": 2.3039,
      "step": 2200
    },
    {
      "epoch": 191.66666666666666,
      "grad_norm": 0.8765939474105835,
      "learning_rate": 9.042083333333333e-05,
      "loss": 2.2825,
      "step": 2300
    },
    {
      "epoch": 200.0,
      "grad_norm": 0.5937686562538147,
      "learning_rate": 9.000416666666666e-05,
      "loss": 2.2597,
      "step": 2400
    },
    {
      "epoch": 208.33333333333334,
      "grad_norm": 0.6040323376655579,
      "learning_rate": 8.95875e-05,
      "loss": 2.2385,
      "step": 2500
    },
    {
      "epoch": 216.66666666666666,
      "grad_norm": 0.5004381537437439,
      "learning_rate": 8.917083333333333e-05,
      "loss": 2.2237,
      "step": 2600
    },
    {
      "epoch": 225.0,
      "grad_norm": 0.618463397026062,
      "learning_rate": 8.875416666666667e-05,
      "loss": 2.1976,
      "step": 2700
    },
    {
      "epoch": 233.33333333333334,
      "grad_norm": 0.5340010523796082,
      "learning_rate": 8.833750000000001e-05,
      "loss": 2.1759,
      "step": 2800
    },
    {
      "epoch": 241.66666666666666,
      "grad_norm": 0.5909866690635681,
      "learning_rate": 8.792083333333334e-05,
      "loss": 2.1618,
      "step": 2900
    },
    {
      "epoch": 250.0,
      "grad_norm": 0.6899327635765076,
      "learning_rate": 8.750416666666668e-05,
      "loss": 2.1411,
      "step": 3000
    },
    {
      "epoch": 250.0,
      "eval_accuracy": 0.0,
      "eval_loss": 2.1294522285461426,
      "eval_runtime": 0.0324,
      "eval_samples_per_second": 1481.89,
      "eval_steps_per_second": 185.236,
      "step": 3000
    },
    {
      "epoch": 258.3333333333333,
      "grad_norm": 0.4687138795852661,
      "learning_rate": 8.70875e-05,
      "loss": 2.1207,
      "step": 3100
    },
    {
      "epoch": 266.6666666666667,
      "grad_norm": 0.5910725593566895,
      "learning_rate": 8.667083333333334e-05,
      "loss": 2.0999,
      "step": 3200
    },
    {
      "epoch": 275.0,
      "grad_norm": 0.5603066682815552,
      "learning_rate": 8.625416666666666e-05,
      "loss": 2.0788,
      "step": 3300
    },
    {
      "epoch": 283.3333333333333,
      "grad_norm": 0.5540595650672913,
      "learning_rate": 8.58375e-05,
      "loss": 2.059,
      "step": 3400
    },
    {
      "epoch": 291.6666666666667,
      "grad_norm": 0.7471890449523926,
      "learning_rate": 8.542083333333333e-05,
      "loss": 2.043,
      "step": 3500
    },
    {
      "epoch": 300.0,
      "grad_norm": 0.4783265292644501,
      "learning_rate": 8.500416666666668e-05,
      "loss": 2.018,
      "step": 3600
    },
    {
      "epoch": 308.3333333333333,
      "grad_norm": 0.6339196562767029,
      "learning_rate": 8.45875e-05,
      "loss": 1.9961,
      "step": 3700
    },
    {
      "epoch": 316.6666666666667,
      "grad_norm": 0.731274425983429,
      "learning_rate": 8.417083333333333e-05,
      "loss": 1.9836,
      "step": 3800
    },
    {
      "epoch": 325.0,
      "grad_norm": 0.5988661646842957,
      "learning_rate": 8.375416666666667e-05,
      "loss": 1.9617,
      "step": 3900
    },
    {
      "epoch": 333.3333333333333,
      "grad_norm": 0.5876109600067139,
      "learning_rate": 8.33375e-05,
      "loss": 1.9412,
      "step": 4000
    },
    {
      "epoch": 333.3333333333333,
      "eval_accuracy": 0.0,
      "eval_loss": 1.9312082529067993,
      "eval_runtime": 0.029,
      "eval_samples_per_second": 1654.028,
      "eval_steps_per_second": 206.753,
      "step": 4000
    },
    {
      "epoch": 341.6666666666667,
      "grad_norm": 0.6149473786354065,
      "learning_rate": 8.292083333333334e-05,
      "loss": 1.9188,
      "step": 4100
    },
    {
      "epoch": 350.0,
      "grad_norm": 0.8243629336357117,
      "learning_rate": 8.250416666666667e-05,
      "loss": 1.9055,
      "step": 4200
    },
    {
      "epoch": 358.3333333333333,
      "grad_norm": 0.46535998582839966,
      "learning_rate": 8.208750000000001e-05,
      "loss": 1.882,
      "step": 4300
    },
    {
      "epoch": 366.6666666666667,
      "grad_norm": 0.5946319699287415,
      "learning_rate": 8.167083333333334e-05,
      "loss": 1.8675,
      "step": 4400
    },
    {
      "epoch": 375.0,
      "grad_norm": 0.6925668716430664,
      "learning_rate": 8.125416666666668e-05,
      "loss": 1.8444,
      "step": 4500
    },
    {
      "epoch": 383.3333333333333,
      "grad_norm": 0.5884158611297607,
      "learning_rate": 8.083749999999999e-05,
      "loss": 1.8229,
      "step": 4600
    },
    {
      "epoch": 391.6666666666667,
      "grad_norm": 0.6214852929115295,
      "learning_rate": 8.042083333333333e-05,
      "loss": 1.8121,
      "step": 4700
    },
    {
      "epoch": 400.0,
      "grad_norm": 0.6849515438079834,
      "learning_rate": 8.000416666666668e-05,
      "loss": 1.7932,
      "step": 4800
    },
    {
      "epoch": 408.3333333333333,
      "grad_norm": 0.692306399345398,
      "learning_rate": 7.95875e-05,
      "loss": 1.7752,
      "step": 4900
    },
    {
      "epoch": 416.6666666666667,
      "grad_norm": 0.47051310539245605,
      "learning_rate": 7.917083333333334e-05,
      "loss": 1.7551,
      "step": 5000
    },
    {
      "epoch": 416.6666666666667,
      "eval_accuracy": 0.1111111111111111,
      "eval_loss": 1.7475229501724243,
      "eval_runtime": 0.0313,
      "eval_samples_per_second": 1533.123,
      "eval_steps_per_second": 191.64,
      "step": 5000
    },
    {
      "epoch": 425.0,
      "grad_norm": 0.6122304201126099,
      "learning_rate": 7.875416666666667e-05,
      "loss": 1.739,
      "step": 5100
    },
    {
      "epoch": 433.3333333333333,
      "grad_norm": 0.7957572340965271,
      "learning_rate": 7.833750000000001e-05,
      "loss": 1.7236,
      "step": 5200
    },
    {
      "epoch": 441.6666666666667,
      "grad_norm": 0.5877705812454224,
      "learning_rate": 7.792083333333333e-05,
      "loss": 1.7054,
      "step": 5300
    },
    {
      "epoch": 450.0,
      "grad_norm": 0.6815887093544006,
      "learning_rate": 7.750416666666667e-05,
      "loss": 1.6893,
      "step": 5400
    },
    {
      "epoch": 458.3333333333333,
      "grad_norm": 0.7172768712043762,
      "learning_rate": 7.70875e-05,
      "loss": 1.676,
      "step": 5500
    },
    {
      "epoch": 466.6666666666667,
      "grad_norm": 0.5959444046020508,
      "learning_rate": 7.667083333333334e-05,
      "loss": 1.6566,
      "step": 5600
    },
    {
      "epoch": 475.0,
      "grad_norm": 0.5832722783088684,
      "learning_rate": 7.625416666666667e-05,
      "loss": 1.6433,
      "step": 5700
    },
    {
      "epoch": 483.3333333333333,
      "grad_norm": 0.6831578016281128,
      "learning_rate": 7.583750000000001e-05,
      "loss": 1.6307,
      "step": 5800
    },
    {
      "epoch": 491.6666666666667,
      "grad_norm": 0.6705030798912048,
      "learning_rate": 7.542083333333333e-05,
      "loss": 1.6148,
      "step": 5900
    },
    {
      "epoch": 500.0,
      "grad_norm": 0.5235075354576111,
      "learning_rate": 7.500416666666668e-05,
      "loss": 1.5967,
      "step": 6000
    },
    {
      "epoch": 500.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.592652440071106,
      "eval_runtime": 0.0337,
      "eval_samples_per_second": 1424.796,
      "eval_steps_per_second": 178.1,
      "step": 6000
    },
    {
      "epoch": 508.3333333333333,
      "grad_norm": 0.5465296506881714,
      "learning_rate": 7.45875e-05,
      "loss": 1.5861,
      "step": 6100
    },
    {
      "epoch": 516.6666666666666,
      "grad_norm": 0.5000943541526794,
      "learning_rate": 7.417083333333333e-05,
      "loss": 1.5752,
      "step": 6200
    },
    {
      "epoch": 525.0,
      "grad_norm": 0.651474118232727,
      "learning_rate": 7.375416666666667e-05,
      "loss": 1.5564,
      "step": 6300
    },
    {
      "epoch": 533.3333333333334,
      "grad_norm": 0.6664116382598877,
      "learning_rate": 7.33375e-05,
      "loss": 1.55,
      "step": 6400
    },
    {
      "epoch": 541.6666666666666,
      "grad_norm": 0.5444555282592773,
      "learning_rate": 7.292083333333334e-05,
      "loss": 1.5297,
      "step": 6500
    },
    {
      "epoch": 550.0,
      "grad_norm": 0.5460193753242493,
      "learning_rate": 7.250416666666667e-05,
      "loss": 1.5223,
      "step": 6600
    },
    {
      "epoch": 558.3333333333334,
      "grad_norm": 0.6637958288192749,
      "learning_rate": 7.208750000000001e-05,
      "loss": 1.5113,
      "step": 6700
    },
    {
      "epoch": 566.6666666666666,
      "grad_norm": 0.6307076811790466,
      "learning_rate": 7.167083333333332e-05,
      "loss": 1.4984,
      "step": 6800
    },
    {
      "epoch": 575.0,
      "grad_norm": 0.6201691031455994,
      "learning_rate": 7.125416666666667e-05,
      "loss": 1.4856,
      "step": 6900
    },
    {
      "epoch": 583.3333333333334,
      "grad_norm": 0.7593543529510498,
      "learning_rate": 7.083750000000001e-05,
      "loss": 1.4751,
      "step": 7000
    },
    {
      "epoch": 583.3333333333334,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.4706863164901733,
      "eval_runtime": 0.031,
      "eval_samples_per_second": 1549.489,
      "eval_steps_per_second": 193.686,
      "step": 7000
    },
    {
      "epoch": 591.6666666666666,
      "grad_norm": 0.714863657951355,
      "learning_rate": 7.042083333333334e-05,
      "loss": 1.4675,
      "step": 7100
    },
    {
      "epoch": 600.0,
      "grad_norm": 0.5217944979667664,
      "learning_rate": 7.000416666666668e-05,
      "loss": 1.4545,
      "step": 7200
    },
    {
      "epoch": 608.3333333333334,
      "grad_norm": 0.5966652035713196,
      "learning_rate": 6.95875e-05,
      "loss": 1.4452,
      "step": 7300
    },
    {
      "epoch": 616.6666666666666,
      "grad_norm": 0.6549707055091858,
      "learning_rate": 6.917083333333335e-05,
      "loss": 1.4338,
      "step": 7400
    },
    {
      "epoch": 625.0,
      "grad_norm": 0.7121021747589111,
      "learning_rate": 6.875416666666667e-05,
      "loss": 1.428,
      "step": 7500
    },
    {
      "epoch": 633.3333333333334,
      "grad_norm": 0.6304645538330078,
      "learning_rate": 6.83375e-05,
      "loss": 1.4146,
      "step": 7600
    },
    {
      "epoch": 641.6666666666666,
      "grad_norm": 0.4589557945728302,
      "learning_rate": 6.792083333333333e-05,
      "loss": 1.4083,
      "step": 7700
    },
    {
      "epoch": 650.0,
      "grad_norm": 0.5165436267852783,
      "learning_rate": 6.750416666666667e-05,
      "loss": 1.4016,
      "step": 7800
    },
    {
      "epoch": 658.3333333333334,
      "grad_norm": 0.6436544060707092,
      "learning_rate": 6.70875e-05,
      "loss": 1.388,
      "step": 7900
    },
    {
      "epoch": 666.6666666666666,
      "grad_norm": 0.679676353931427,
      "learning_rate": 6.667083333333334e-05,
      "loss": 1.3854,
      "step": 8000
    },
    {
      "epoch": 666.6666666666666,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.3788806200027466,
      "eval_runtime": 0.0312,
      "eval_samples_per_second": 1536.481,
      "eval_steps_per_second": 192.06,
      "step": 8000
    },
    {
      "epoch": 675.0,
      "grad_norm": 0.5151451230049133,
      "learning_rate": 6.625416666666667e-05,
      "loss": 1.3759,
      "step": 8100
    },
    {
      "epoch": 683.3333333333334,
      "grad_norm": 0.5730345845222473,
      "learning_rate": 6.583750000000001e-05,
      "loss": 1.3689,
      "step": 8200
    },
    {
      "epoch": 691.6666666666666,
      "grad_norm": 0.7313722372055054,
      "learning_rate": 6.542083333333334e-05,
      "loss": 1.3613,
      "step": 8300
    },
    {
      "epoch": 700.0,
      "grad_norm": 0.48919039964675903,
      "learning_rate": 6.500416666666666e-05,
      "loss": 1.3504,
      "step": 8400
    },
    {
      "epoch": 708.3333333333334,
      "grad_norm": 0.5409805178642273,
      "learning_rate": 6.45875e-05,
      "loss": 1.3455,
      "step": 8500
    },
    {
      "epoch": 716.6666666666666,
      "grad_norm": 0.5303018689155579,
      "learning_rate": 6.417083333333333e-05,
      "loss": 1.3404,
      "step": 8600
    },
    {
      "epoch": 725.0,
      "grad_norm": 0.5314298272132874,
      "learning_rate": 6.375416666666667e-05,
      "loss": 1.332,
      "step": 8700
    },
    {
      "epoch": 733.3333333333334,
      "grad_norm": 0.5693715214729309,
      "learning_rate": 6.33375e-05,
      "loss": 1.3274,
      "step": 8800
    },
    {
      "epoch": 741.6666666666666,
      "grad_norm": 0.5135254859924316,
      "learning_rate": 6.292083333333334e-05,
      "loss": 1.3192,
      "step": 8900
    },
    {
      "epoch": 750.0,
      "grad_norm": 0.5605344176292419,
      "learning_rate": 6.250416666666667e-05,
      "loss": 1.3141,
      "step": 9000
    },
    {
      "epoch": 750.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.311171293258667,
      "eval_runtime": 0.0297,
      "eval_samples_per_second": 1617.406,
      "eval_steps_per_second": 202.176,
      "step": 9000
    },
    {
      "epoch": 758.3333333333334,
      "grad_norm": 0.925197422504425,
      "learning_rate": 6.20875e-05,
      "loss": 1.3097,
      "step": 9100
    },
    {
      "epoch": 766.6666666666666,
      "grad_norm": 0.48476675152778625,
      "learning_rate": 6.167083333333334e-05,
      "loss": 1.3001,
      "step": 9200
    },
    {
      "epoch": 775.0,
      "grad_norm": 0.532160758972168,
      "learning_rate": 6.125416666666667e-05,
      "loss": 1.2989,
      "step": 9300
    },
    {
      "epoch": 783.3333333333334,
      "grad_norm": 0.43017223477363586,
      "learning_rate": 6.08375e-05,
      "loss": 1.292,
      "step": 9400
    },
    {
      "epoch": 791.6666666666666,
      "grad_norm": 0.4551057517528534,
      "learning_rate": 6.0420833333333336e-05,
      "loss": 1.2875,
      "step": 9500
    },
    {
      "epoch": 800.0,
      "grad_norm": 0.5898595452308655,
      "learning_rate": 6.000416666666667e-05,
      "loss": 1.2817,
      "step": 9600
    },
    {
      "epoch": 808.3333333333334,
      "grad_norm": 0.6216546893119812,
      "learning_rate": 5.9587500000000005e-05,
      "loss": 1.2753,
      "step": 9700
    },
    {
      "epoch": 816.6666666666666,
      "grad_norm": 0.8155809044837952,
      "learning_rate": 5.917083333333333e-05,
      "loss": 1.2756,
      "step": 9800
    },
    {
      "epoch": 825.0,
      "grad_norm": 0.7431382536888123,
      "learning_rate": 5.875416666666667e-05,
      "loss": 1.2673,
      "step": 9900
    },
    {
      "epoch": 833.3333333333334,
      "grad_norm": 0.45613834261894226,
      "learning_rate": 5.83375e-05,
      "loss": 1.2626,
      "step": 10000
    },
    {
      "epoch": 833.3333333333334,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.2615894079208374,
      "eval_runtime": 0.0313,
      "eval_samples_per_second": 1532.131,
      "eval_steps_per_second": 191.516,
      "step": 10000
    },
    {
      "epoch": 841.6666666666666,
      "grad_norm": 0.7146485447883606,
      "learning_rate": 5.7920833333333336e-05,
      "loss": 1.262,
      "step": 10100
    },
    {
      "epoch": 850.0,
      "grad_norm": 0.5957129597663879,
      "learning_rate": 5.750416666666667e-05,
      "loss": 1.2543,
      "step": 10200
    },
    {
      "epoch": 858.3333333333334,
      "grad_norm": 0.5985375642776489,
      "learning_rate": 5.7087500000000005e-05,
      "loss": 1.2491,
      "step": 10300
    },
    {
      "epoch": 866.6666666666666,
      "grad_norm": 0.5014562606811523,
      "learning_rate": 5.667083333333334e-05,
      "loss": 1.2505,
      "step": 10400
    },
    {
      "epoch": 875.0,
      "grad_norm": 0.5237607359886169,
      "learning_rate": 5.6254166666666674e-05,
      "loss": 1.2436,
      "step": 10500
    },
    {
      "epoch": 883.3333333333334,
      "grad_norm": 0.665937602519989,
      "learning_rate": 5.5837499999999995e-05,
      "loss": 1.2391,
      "step": 10600
    },
    {
      "epoch": 891.6666666666666,
      "grad_norm": 0.6419817209243774,
      "learning_rate": 5.542083333333333e-05,
      "loss": 1.2414,
      "step": 10700
    },
    {
      "epoch": 900.0,
      "grad_norm": 0.5191245079040527,
      "learning_rate": 5.500416666666667e-05,
      "loss": 1.2299,
      "step": 10800
    },
    {
      "epoch": 908.3333333333334,
      "grad_norm": 0.7462837100028992,
      "learning_rate": 5.4587500000000005e-05,
      "loss": 1.2309,
      "step": 10900
    },
    {
      "epoch": 916.6666666666666,
      "grad_norm": 0.7026402354240417,
      "learning_rate": 5.417083333333334e-05,
      "loss": 1.224,
      "step": 11000
    },
    {
      "epoch": 916.6666666666666,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.2251195907592773,
      "eval_runtime": 0.03,
      "eval_samples_per_second": 1602.243,
      "eval_steps_per_second": 200.28,
      "step": 11000
    },
    {
      "epoch": 925.0,
      "grad_norm": 0.6570234894752502,
      "learning_rate": 5.3754166666666674e-05,
      "loss": 1.2256,
      "step": 11100
    },
    {
      "epoch": 933.3333333333334,
      "grad_norm": 0.7420072555541992,
      "learning_rate": 5.333750000000001e-05,
      "loss": 1.2272,
      "step": 11200
    },
    {
      "epoch": 941.6666666666666,
      "grad_norm": 0.5007108449935913,
      "learning_rate": 5.292083333333333e-05,
      "loss": 1.2105,
      "step": 11300
    },
    {
      "epoch": 950.0,
      "grad_norm": 0.6749826669692993,
      "learning_rate": 5.2504166666666664e-05,
      "loss": 1.2155,
      "step": 11400
    },
    {
      "epoch": 958.3333333333334,
      "grad_norm": 0.4446224570274353,
      "learning_rate": 5.20875e-05,
      "loss": 1.212,
      "step": 11500
    },
    {
      "epoch": 966.6666666666666,
      "grad_norm": 0.46584558486938477,
      "learning_rate": 5.1670833333333333e-05,
      "loss": 1.2097,
      "step": 11600
    },
    {
      "epoch": 975.0,
      "grad_norm": 0.4884452223777771,
      "learning_rate": 5.125416666666667e-05,
      "loss": 1.2067,
      "step": 11700
    },
    {
      "epoch": 983.3333333333334,
      "grad_norm": 0.6299191117286682,
      "learning_rate": 5.08375e-05,
      "loss": 1.2032,
      "step": 11800
    },
    {
      "epoch": 991.6666666666666,
      "grad_norm": 0.6531593799591064,
      "learning_rate": 5.042083333333334e-05,
      "loss": 1.2039,
      "step": 11900
    },
    {
      "epoch": 1000.0,
      "grad_norm": 0.43738189339637756,
      "learning_rate": 5.000416666666667e-05,
      "loss": 1.1985,
      "step": 12000
    },
    {
      "epoch": 1000.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.198221206665039,
      "eval_runtime": 0.0331,
      "eval_samples_per_second": 1450.992,
      "eval_steps_per_second": 181.374,
      "step": 12000
    },
    {
      "epoch": 1008.3333333333334,
      "grad_norm": 0.5184521675109863,
      "learning_rate": 4.9587500000000006e-05,
      "loss": 1.197,
      "step": 12100
    },
    {
      "epoch": 1016.6666666666666,
      "grad_norm": 0.5186393857002258,
      "learning_rate": 4.917083333333334e-05,
      "loss": 1.1946,
      "step": 12200
    },
    {
      "epoch": 1025.0,
      "grad_norm": 0.632483184337616,
      "learning_rate": 4.875416666666667e-05,
      "loss": 1.1932,
      "step": 12300
    },
    {
      "epoch": 1033.3333333333333,
      "grad_norm": 0.6350398063659668,
      "learning_rate": 4.83375e-05,
      "loss": 1.1912,
      "step": 12400
    },
    {
      "epoch": 1041.6666666666667,
      "grad_norm": 0.5078209638595581,
      "learning_rate": 4.792083333333334e-05,
      "loss": 1.1884,
      "step": 12500
    },
    {
      "epoch": 1050.0,
      "grad_norm": 0.6096820831298828,
      "learning_rate": 4.7504166666666665e-05,
      "loss": 1.186,
      "step": 12600
    },
    {
      "epoch": 1058.3333333333333,
      "grad_norm": 0.5128987431526184,
      "learning_rate": 4.70875e-05,
      "loss": 1.1888,
      "step": 12700
    },
    {
      "epoch": 1066.6666666666667,
      "grad_norm": 0.49676260352134705,
      "learning_rate": 4.6670833333333334e-05,
      "loss": 1.1794,
      "step": 12800
    },
    {
      "epoch": 1075.0,
      "grad_norm": 0.511321485042572,
      "learning_rate": 4.625416666666667e-05,
      "loss": 1.18,
      "step": 12900
    },
    {
      "epoch": 1083.3333333333333,
      "grad_norm": 0.6031290292739868,
      "learning_rate": 4.58375e-05,
      "loss": 1.1765,
      "step": 13000
    },
    {
      "epoch": 1083.3333333333333,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1781212091445923,
      "eval_runtime": 0.0324,
      "eval_samples_per_second": 1483.222,
      "eval_steps_per_second": 185.403,
      "step": 13000
    },
    {
      "epoch": 1091.6666666666667,
      "grad_norm": 0.5112612247467041,
      "learning_rate": 4.542083333333334e-05,
      "loss": 1.1786,
      "step": 13100
    },
    {
      "epoch": 1100.0,
      "grad_norm": 0.47424793243408203,
      "learning_rate": 4.500416666666667e-05,
      "loss": 1.177,
      "step": 13200
    },
    {
      "epoch": 1108.3333333333333,
      "grad_norm": 0.48695313930511475,
      "learning_rate": 4.4587500000000006e-05,
      "loss": 1.1716,
      "step": 13300
    },
    {
      "epoch": 1116.6666666666667,
      "grad_norm": 0.45062363147735596,
      "learning_rate": 4.4170833333333334e-05,
      "loss": 1.1749,
      "step": 13400
    },
    {
      "epoch": 1125.0,
      "grad_norm": 0.47126057744026184,
      "learning_rate": 4.375416666666667e-05,
      "loss": 1.1707,
      "step": 13500
    },
    {
      "epoch": 1133.3333333333333,
      "grad_norm": 0.4777139127254486,
      "learning_rate": 4.33375e-05,
      "loss": 1.168,
      "step": 13600
    },
    {
      "epoch": 1141.6666666666667,
      "grad_norm": 0.5064113736152649,
      "learning_rate": 4.292083333333334e-05,
      "loss": 1.1702,
      "step": 13700
    },
    {
      "epoch": 1150.0,
      "grad_norm": 0.6166946887969971,
      "learning_rate": 4.2504166666666665e-05,
      "loss": 1.1654,
      "step": 13800
    },
    {
      "epoch": 1158.3333333333333,
      "grad_norm": 0.494022935628891,
      "learning_rate": 4.20875e-05,
      "loss": 1.1641,
      "step": 13900
    },
    {
      "epoch": 1166.6666666666667,
      "grad_norm": 0.5007319450378418,
      "learning_rate": 4.1670833333333334e-05,
      "loss": 1.1632,
      "step": 14000
    },
    {
      "epoch": 1166.6666666666667,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1629260778427124,
      "eval_runtime": 0.0341,
      "eval_samples_per_second": 1407.76,
      "eval_steps_per_second": 175.97,
      "step": 14000
    },
    {
      "epoch": 1175.0,
      "grad_norm": 1.0092177391052246,
      "learning_rate": 4.125416666666667e-05,
      "loss": 1.1637,
      "step": 14100
    },
    {
      "epoch": 1183.3333333333333,
      "grad_norm": 0.5052011013031006,
      "learning_rate": 4.08375e-05,
      "loss": 1.1597,
      "step": 14200
    },
    {
      "epoch": 1191.6666666666667,
      "grad_norm": 0.47495245933532715,
      "learning_rate": 4.042083333333334e-05,
      "loss": 1.1614,
      "step": 14300
    },
    {
      "epoch": 1200.0,
      "grad_norm": 0.493790864944458,
      "learning_rate": 4.000416666666667e-05,
      "loss": 1.1583,
      "step": 14400
    },
    {
      "epoch": 1208.3333333333333,
      "grad_norm": 0.4815879166126251,
      "learning_rate": 3.95875e-05,
      "loss": 1.1584,
      "step": 14500
    },
    {
      "epoch": 1216.6666666666667,
      "grad_norm": 0.4668075442314148,
      "learning_rate": 3.9170833333333335e-05,
      "loss": 1.1544,
      "step": 14600
    },
    {
      "epoch": 1225.0,
      "grad_norm": 0.6175908446311951,
      "learning_rate": 3.875416666666667e-05,
      "loss": 1.156,
      "step": 14700
    },
    {
      "epoch": 1233.3333333333333,
      "grad_norm": 0.4562186598777771,
      "learning_rate": 3.8337500000000004e-05,
      "loss": 1.1541,
      "step": 14800
    },
    {
      "epoch": 1241.6666666666667,
      "grad_norm": 0.6359095573425293,
      "learning_rate": 3.792083333333333e-05,
      "loss": 1.1556,
      "step": 14900
    },
    {
      "epoch": 1250.0,
      "grad_norm": 0.6147501468658447,
      "learning_rate": 3.7504166666666666e-05,
      "loss": 1.1492,
      "step": 15000
    },
    {
      "epoch": 1250.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1513322591781616,
      "eval_runtime": 0.0354,
      "eval_samples_per_second": 1356.155,
      "eval_steps_per_second": 169.519,
      "step": 15000
    },
    {
      "epoch": 1258.3333333333333,
      "grad_norm": 0.4394721984863281,
      "learning_rate": 3.70875e-05,
      "loss": 1.1496,
      "step": 15100
    },
    {
      "epoch": 1266.6666666666667,
      "grad_norm": 0.48764464259147644,
      "learning_rate": 3.6670833333333335e-05,
      "loss": 1.1511,
      "step": 15200
    },
    {
      "epoch": 1275.0,
      "grad_norm": 0.5679791569709778,
      "learning_rate": 3.625416666666667e-05,
      "loss": 1.1491,
      "step": 15300
    },
    {
      "epoch": 1283.3333333333333,
      "grad_norm": 0.5071014165878296,
      "learning_rate": 3.5837500000000004e-05,
      "loss": 1.1463,
      "step": 15400
    },
    {
      "epoch": 1291.6666666666667,
      "grad_norm": 0.6192807555198669,
      "learning_rate": 3.542083333333334e-05,
      "loss": 1.1488,
      "step": 15500
    },
    {
      "epoch": 1300.0,
      "grad_norm": 0.6571966409683228,
      "learning_rate": 3.5004166666666666e-05,
      "loss": 1.1462,
      "step": 15600
    },
    {
      "epoch": 1308.3333333333333,
      "grad_norm": 0.6056457161903381,
      "learning_rate": 3.45875e-05,
      "loss": 1.1444,
      "step": 15700
    },
    {
      "epoch": 1316.6666666666667,
      "grad_norm": 0.4696842133998871,
      "learning_rate": 3.4170833333333335e-05,
      "loss": 1.1422,
      "step": 15800
    },
    {
      "epoch": 1325.0,
      "grad_norm": 0.6271392703056335,
      "learning_rate": 3.375416666666667e-05,
      "loss": 1.1468,
      "step": 15900
    },
    {
      "epoch": 1333.3333333333333,
      "grad_norm": 0.6083215475082397,
      "learning_rate": 3.33375e-05,
      "loss": 1.1416,
      "step": 16000
    },
    {
      "epoch": 1333.3333333333333,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1423835754394531,
      "eval_runtime": 0.0325,
      "eval_samples_per_second": 1476.781,
      "eval_steps_per_second": 184.598,
      "step": 16000
    },
    {
      "epoch": 1341.6666666666667,
      "grad_norm": 0.5221809148788452,
      "learning_rate": 3.292083333333333e-05,
      "loss": 1.1451,
      "step": 16100
    },
    {
      "epoch": 1350.0,
      "grad_norm": 0.9379390478134155,
      "learning_rate": 3.2504166666666666e-05,
      "loss": 1.1395,
      "step": 16200
    },
    {
      "epoch": 1358.3333333333333,
      "grad_norm": 0.5248845219612122,
      "learning_rate": 3.20875e-05,
      "loss": 1.1415,
      "step": 16300
    },
    {
      "epoch": 1366.6666666666667,
      "grad_norm": 0.6206213235855103,
      "learning_rate": 3.1670833333333335e-05,
      "loss": 1.1388,
      "step": 16400
    },
    {
      "epoch": 1375.0,
      "grad_norm": 0.498672753572464,
      "learning_rate": 3.125416666666667e-05,
      "loss": 1.1392,
      "step": 16500
    },
    {
      "epoch": 1383.3333333333333,
      "grad_norm": 0.5771470665931702,
      "learning_rate": 3.0837500000000004e-05,
      "loss": 1.1355,
      "step": 16600
    },
    {
      "epoch": 1391.6666666666667,
      "grad_norm": 0.6247583031654358,
      "learning_rate": 3.042083333333334e-05,
      "loss": 1.1416,
      "step": 16700
    },
    {
      "epoch": 1400.0,
      "grad_norm": 0.6681264042854309,
      "learning_rate": 3.0004166666666666e-05,
      "loss": 1.1361,
      "step": 16800
    },
    {
      "epoch": 1408.3333333333333,
      "grad_norm": 0.6263939142227173,
      "learning_rate": 2.95875e-05,
      "loss": 1.1373,
      "step": 16900
    },
    {
      "epoch": 1416.6666666666667,
      "grad_norm": 0.4689638316631317,
      "learning_rate": 2.9170833333333335e-05,
      "loss": 1.1346,
      "step": 17000
    },
    {
      "epoch": 1416.6666666666667,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.135434627532959,
      "eval_runtime": 0.0307,
      "eval_samples_per_second": 1564.346,
      "eval_steps_per_second": 195.543,
      "step": 17000
    },
    {
      "epoch": 1425.0,
      "grad_norm": 0.6333588361740112,
      "learning_rate": 2.8754166666666667e-05,
      "loss": 1.1355,
      "step": 17100
    },
    {
      "epoch": 1433.3333333333333,
      "grad_norm": 0.5095058679580688,
      "learning_rate": 2.83375e-05,
      "loss": 1.1374,
      "step": 17200
    },
    {
      "epoch": 1441.6666666666667,
      "grad_norm": 0.6440286040306091,
      "learning_rate": 2.7920833333333336e-05,
      "loss": 1.134,
      "step": 17300
    },
    {
      "epoch": 1450.0,
      "grad_norm": 0.5418684482574463,
      "learning_rate": 2.750416666666667e-05,
      "loss": 1.1306,
      "step": 17400
    },
    {
      "epoch": 1458.3333333333333,
      "grad_norm": 0.6474710702896118,
      "learning_rate": 2.7087499999999998e-05,
      "loss": 1.1321,
      "step": 17500
    },
    {
      "epoch": 1466.6666666666667,
      "grad_norm": 0.47032055258750916,
      "learning_rate": 2.6670833333333332e-05,
      "loss": 1.1352,
      "step": 17600
    },
    {
      "epoch": 1475.0,
      "grad_norm": 0.5050567388534546,
      "learning_rate": 2.625416666666667e-05,
      "loss": 1.1297,
      "step": 17700
    },
    {
      "epoch": 1483.3333333333333,
      "grad_norm": 0.439967542886734,
      "learning_rate": 2.5837500000000005e-05,
      "loss": 1.1297,
      "step": 17800
    },
    {
      "epoch": 1491.6666666666667,
      "grad_norm": 0.48769402503967285,
      "learning_rate": 2.5420833333333332e-05,
      "loss": 1.1343,
      "step": 17900
    },
    {
      "epoch": 1500.0,
      "grad_norm": 0.6378214955329895,
      "learning_rate": 2.5004166666666667e-05,
      "loss": 1.1285,
      "step": 18000
    },
    {
      "epoch": 1500.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1300476789474487,
      "eval_runtime": 0.0349,
      "eval_samples_per_second": 1375.755,
      "eval_steps_per_second": 171.969,
      "step": 18000
    },
    {
      "epoch": 1508.3333333333333,
      "grad_norm": 0.656335175037384,
      "learning_rate": 2.45875e-05,
      "loss": 1.1289,
      "step": 18100
    },
    {
      "epoch": 1516.6666666666667,
      "grad_norm": 0.5033442974090576,
      "learning_rate": 2.4170833333333336e-05,
      "loss": 1.1314,
      "step": 18200
    },
    {
      "epoch": 1525.0,
      "grad_norm": 0.4505973160266876,
      "learning_rate": 2.375416666666667e-05,
      "loss": 1.1279,
      "step": 18300
    },
    {
      "epoch": 1533.3333333333333,
      "grad_norm": 0.5007722973823547,
      "learning_rate": 2.33375e-05,
      "loss": 1.1284,
      "step": 18400
    },
    {
      "epoch": 1541.6666666666667,
      "grad_norm": 0.6377403736114502,
      "learning_rate": 2.2920833333333333e-05,
      "loss": 1.1303,
      "step": 18500
    },
    {
      "epoch": 1550.0,
      "grad_norm": 0.44898998737335205,
      "learning_rate": 2.2504166666666667e-05,
      "loss": 1.1256,
      "step": 18600
    },
    {
      "epoch": 1558.3333333333333,
      "grad_norm": 0.6496790647506714,
      "learning_rate": 2.2087499999999998e-05,
      "loss": 1.128,
      "step": 18700
    },
    {
      "epoch": 1566.6666666666667,
      "grad_norm": 0.5216365456581116,
      "learning_rate": 2.1670833333333336e-05,
      "loss": 1.1267,
      "step": 18800
    },
    {
      "epoch": 1575.0,
      "grad_norm": 0.6307743191719055,
      "learning_rate": 2.1254166666666667e-05,
      "loss": 1.1259,
      "step": 18900
    },
    {
      "epoch": 1583.3333333333333,
      "grad_norm": 0.4713187515735626,
      "learning_rate": 2.08375e-05,
      "loss": 1.1263,
      "step": 19000
    },
    {
      "epoch": 1583.3333333333333,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1259020566940308,
      "eval_runtime": 0.0358,
      "eval_samples_per_second": 1340.185,
      "eval_steps_per_second": 167.523,
      "step": 19000
    },
    {
      "epoch": 1591.6666666666667,
      "grad_norm": 0.5046087503433228,
      "learning_rate": 2.0420833333333333e-05,
      "loss": 1.1282,
      "step": 19100
    },
    {
      "epoch": 1600.0,
      "grad_norm": 0.5331941246986389,
      "learning_rate": 2.0004166666666667e-05,
      "loss": 1.1227,
      "step": 19200
    },
    {
      "epoch": 1608.3333333333333,
      "grad_norm": 0.5169787406921387,
      "learning_rate": 1.9587500000000002e-05,
      "loss": 1.1252,
      "step": 19300
    },
    {
      "epoch": 1616.6666666666667,
      "grad_norm": 0.4735008180141449,
      "learning_rate": 1.9170833333333336e-05,
      "loss": 1.123,
      "step": 19400
    },
    {
      "epoch": 1625.0,
      "grad_norm": 0.4887326955795288,
      "learning_rate": 1.8754166666666667e-05,
      "loss": 1.126,
      "step": 19500
    },
    {
      "epoch": 1633.3333333333333,
      "grad_norm": 0.7041372060775757,
      "learning_rate": 1.8337500000000002e-05,
      "loss": 1.1252,
      "step": 19600
    },
    {
      "epoch": 1641.6666666666667,
      "grad_norm": 0.6861222386360168,
      "learning_rate": 1.7920833333333333e-05,
      "loss": 1.1227,
      "step": 19700
    },
    {
      "epoch": 1650.0,
      "grad_norm": 0.8678483366966248,
      "learning_rate": 1.7504166666666667e-05,
      "loss": 1.1235,
      "step": 19800
    },
    {
      "epoch": 1658.3333333333333,
      "grad_norm": 0.5029279589653015,
      "learning_rate": 1.7087500000000002e-05,
      "loss": 1.1235,
      "step": 19900
    },
    {
      "epoch": 1666.6666666666667,
      "grad_norm": 0.5067727565765381,
      "learning_rate": 1.6670833333333333e-05,
      "loss": 1.1254,
      "step": 20000
    },
    {
      "epoch": 1666.6666666666667,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.122769832611084,
      "eval_runtime": 0.0339,
      "eval_samples_per_second": 1415.092,
      "eval_steps_per_second": 176.887,
      "step": 20000
    },
    {
      "epoch": 1675.0,
      "grad_norm": 0.572310209274292,
      "learning_rate": 1.6254166666666668e-05,
      "loss": 1.12,
      "step": 20100
    },
    {
      "epoch": 1683.3333333333333,
      "grad_norm": 0.5324277281761169,
      "learning_rate": 1.58375e-05,
      "loss": 1.1226,
      "step": 20200
    },
    {
      "epoch": 1691.6666666666667,
      "grad_norm": 0.5018193125724792,
      "learning_rate": 1.5420833333333333e-05,
      "loss": 1.1208,
      "step": 20300
    },
    {
      "epoch": 1700.0,
      "grad_norm": 0.636792778968811,
      "learning_rate": 1.5004166666666666e-05,
      "loss": 1.123,
      "step": 20400
    },
    {
      "epoch": 1708.3333333333333,
      "grad_norm": 0.4940997064113617,
      "learning_rate": 1.45875e-05,
      "loss": 1.12,
      "step": 20500
    },
    {
      "epoch": 1716.6666666666667,
      "grad_norm": 0.5401731729507446,
      "learning_rate": 1.4170833333333333e-05,
      "loss": 1.1214,
      "step": 20600
    },
    {
      "epoch": 1725.0,
      "grad_norm": 0.5438769459724426,
      "learning_rate": 1.3754166666666668e-05,
      "loss": 1.1229,
      "step": 20700
    },
    {
      "epoch": 1733.3333333333333,
      "grad_norm": 0.6715571880340576,
      "learning_rate": 1.33375e-05,
      "loss": 1.1222,
      "step": 20800
    },
    {
      "epoch": 1741.6666666666667,
      "grad_norm": 0.4606400728225708,
      "learning_rate": 1.2920833333333335e-05,
      "loss": 1.1196,
      "step": 20900
    },
    {
      "epoch": 1750.0,
      "grad_norm": 0.6107940077781677,
      "learning_rate": 1.2504166666666666e-05,
      "loss": 1.1206,
      "step": 21000
    },
    {
      "epoch": 1750.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1204780340194702,
      "eval_runtime": 0.0344,
      "eval_samples_per_second": 1396.114,
      "eval_steps_per_second": 174.514,
      "step": 21000
    },
    {
      "epoch": 1758.3333333333333,
      "grad_norm": 0.4805562496185303,
      "learning_rate": 1.20875e-05,
      "loss": 1.1196,
      "step": 21100
    },
    {
      "epoch": 1766.6666666666667,
      "grad_norm": 0.45693787932395935,
      "learning_rate": 1.1670833333333334e-05,
      "loss": 1.1202,
      "step": 21200
    },
    {
      "epoch": 1775.0,
      "grad_norm": 0.6482232809066772,
      "learning_rate": 1.1254166666666666e-05,
      "loss": 1.1209,
      "step": 21300
    },
    {
      "epoch": 1783.3333333333333,
      "grad_norm": 0.4947330355644226,
      "learning_rate": 1.08375e-05,
      "loss": 1.1179,
      "step": 21400
    },
    {
      "epoch": 1791.6666666666667,
      "grad_norm": 0.7721308469772339,
      "learning_rate": 1.0420833333333334e-05,
      "loss": 1.122,
      "step": 21500
    },
    {
      "epoch": 1800.0,
      "grad_norm": 0.46320968866348267,
      "learning_rate": 1.0004166666666666e-05,
      "loss": 1.1193,
      "step": 21600
    },
    {
      "epoch": 1808.3333333333333,
      "grad_norm": 0.6377394199371338,
      "learning_rate": 9.587500000000001e-06,
      "loss": 1.1209,
      "step": 21700
    },
    {
      "epoch": 1816.6666666666667,
      "grad_norm": 0.6598885655403137,
      "learning_rate": 9.170833333333334e-06,
      "loss": 1.1185,
      "step": 21800
    },
    {
      "epoch": 1825.0,
      "grad_norm": 0.7407922148704529,
      "learning_rate": 8.754166666666668e-06,
      "loss": 1.1184,
      "step": 21900
    },
    {
      "epoch": 1833.3333333333333,
      "grad_norm": 0.6242592930793762,
      "learning_rate": 8.337500000000001e-06,
      "loss": 1.1177,
      "step": 22000
    },
    {
      "epoch": 1833.3333333333333,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1189159154891968,
      "eval_runtime": 0.0363,
      "eval_samples_per_second": 1320.789,
      "eval_steps_per_second": 165.099,
      "step": 22000
    }
  ],
  "logging_steps": 100,
  "max_steps": 24000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2000,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
