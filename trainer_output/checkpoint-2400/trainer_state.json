{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 200.0,
  "eval_steps": 200,
  "global_step": 2400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.62308269739151,
      "learning_rate": 0.0009795833333333334,
      "loss": 2.8232,
      "step": 50
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.6307672262191772,
      "learning_rate": 0.00095875,
      "loss": 2.6958,
      "step": 100
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.5503997206687927,
      "learning_rate": 0.0009379166666666667,
      "loss": 2.5524,
      "step": 150
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.7874876856803894,
      "learning_rate": 0.0009170833333333333,
      "loss": 2.4067,
      "step": 200
    },
    {
      "epoch": 16.666666666666668,
      "eval_accuracy": 0.0,
      "eval_loss": 2.3467371463775635,
      "eval_runtime": 0.0793,
      "eval_samples_per_second": 605.273,
      "eval_steps_per_second": 75.659,
      "step": 200
    },
    {
      "epoch": 20.833333333333332,
      "grad_norm": 0.5901336073875427,
      "learning_rate": 0.00089625,
      "loss": 2.2948,
      "step": 250
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.4787656366825104,
      "learning_rate": 0.0008754166666666666,
      "loss": 2.1907,
      "step": 300
    },
    {
      "epoch": 29.166666666666668,
      "grad_norm": 0.5931745171546936,
      "learning_rate": 0.0008545833333333334,
      "loss": 2.0785,
      "step": 350
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 0.7144402265548706,
      "learning_rate": 0.00083375,
      "loss": 1.9745,
      "step": 400
    },
    {
      "epoch": 33.333333333333336,
      "eval_accuracy": 0.0,
      "eval_loss": 1.9168542623519897,
      "eval_runtime": 0.0358,
      "eval_samples_per_second": 1339.659,
      "eval_steps_per_second": 167.457,
      "step": 400
    },
    {
      "epoch": 37.5,
      "grad_norm": 0.49541258811950684,
      "learning_rate": 0.0008129166666666666,
      "loss": 1.8625,
      "step": 450
    },
    {
      "epoch": 41.666666666666664,
      "grad_norm": 0.6001492142677307,
      "learning_rate": 0.0007920833333333333,
      "loss": 1.7766,
      "step": 500
    },
    {
      "epoch": 45.833333333333336,
      "grad_norm": 0.5548414587974548,
      "learning_rate": 0.00077125,
      "loss": 1.6632,
      "step": 550
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.46512433886528015,
      "learning_rate": 0.0007504166666666666,
      "loss": 1.6017,
      "step": 600
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.555651068687439,
      "eval_runtime": 0.0321,
      "eval_samples_per_second": 1497.097,
      "eval_steps_per_second": 187.137,
      "step": 600
    },
    {
      "epoch": 54.166666666666664,
      "grad_norm": 0.6788373589515686,
      "learning_rate": 0.0007295833333333334,
      "loss": 1.5201,
      "step": 650
    },
    {
      "epoch": 58.333333333333336,
      "grad_norm": 0.5246608853340149,
      "learning_rate": 0.00070875,
      "loss": 1.4686,
      "step": 700
    },
    {
      "epoch": 62.5,
      "grad_norm": 0.7544099688529968,
      "learning_rate": 0.0006879166666666666,
      "loss": 1.4196,
      "step": 750
    },
    {
      "epoch": 66.66666666666667,
      "grad_norm": 0.7984893918037415,
      "learning_rate": 0.0006670833333333333,
      "loss": 1.3738,
      "step": 800
    },
    {
      "epoch": 66.66666666666667,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.3544725179672241,
      "eval_runtime": 0.0299,
      "eval_samples_per_second": 1606.539,
      "eval_steps_per_second": 200.817,
      "step": 800
    },
    {
      "epoch": 70.83333333333333,
      "grad_norm": 0.5062999725341797,
      "learning_rate": 0.00064625,
      "loss": 1.3361,
      "step": 850
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.4765576422214508,
      "learning_rate": 0.0006254166666666666,
      "loss": 1.312,
      "step": 900
    },
    {
      "epoch": 79.16666666666667,
      "grad_norm": 0.6789484620094299,
      "learning_rate": 0.0006045833333333334,
      "loss": 1.2868,
      "step": 950
    },
    {
      "epoch": 83.33333333333333,
      "grad_norm": 0.5028976798057556,
      "learning_rate": 0.00058375,
      "loss": 1.2633,
      "step": 1000
    },
    {
      "epoch": 83.33333333333333,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.255635142326355,
      "eval_runtime": 0.0367,
      "eval_samples_per_second": 1309.578,
      "eval_steps_per_second": 163.697,
      "step": 1000
    },
    {
      "epoch": 87.5,
      "grad_norm": 0.5851114988327026,
      "learning_rate": 0.0005629166666666666,
      "loss": 1.2504,
      "step": 1050
    },
    {
      "epoch": 91.66666666666667,
      "grad_norm": 0.4527612030506134,
      "learning_rate": 0.0005420833333333333,
      "loss": 1.2353,
      "step": 1100
    },
    {
      "epoch": 95.83333333333333,
      "grad_norm": 0.5056387186050415,
      "learning_rate": 0.00052125,
      "loss": 1.2222,
      "step": 1150
    },
    {
      "epoch": 100.0,
      "grad_norm": 0.6481716632843018,
      "learning_rate": 0.0005004166666666666,
      "loss": 1.2081,
      "step": 1200
    },
    {
      "epoch": 100.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.2043402194976807,
      "eval_runtime": 0.0276,
      "eval_samples_per_second": 1736.218,
      "eval_steps_per_second": 217.027,
      "step": 1200
    },
    {
      "epoch": 104.16666666666667,
      "grad_norm": 0.9326635599136353,
      "learning_rate": 0.0004795833333333333,
      "loss": 1.2014,
      "step": 1250
    },
    {
      "epoch": 108.33333333333333,
      "grad_norm": 0.49354517459869385,
      "learning_rate": 0.00045875,
      "loss": 1.1911,
      "step": 1300
    },
    {
      "epoch": 112.5,
      "grad_norm": 0.4719180464744568,
      "learning_rate": 0.0004379166666666667,
      "loss": 1.1852,
      "step": 1350
    },
    {
      "epoch": 116.66666666666667,
      "grad_norm": 0.623673677444458,
      "learning_rate": 0.0004170833333333333,
      "loss": 1.1797,
      "step": 1400
    },
    {
      "epoch": 116.66666666666667,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1753864288330078,
      "eval_runtime": 0.0278,
      "eval_samples_per_second": 1723.583,
      "eval_steps_per_second": 215.448,
      "step": 1400
    },
    {
      "epoch": 120.83333333333333,
      "grad_norm": 0.5167861580848694,
      "learning_rate": 0.00039625,
      "loss": 1.1729,
      "step": 1450
    },
    {
      "epoch": 125.0,
      "grad_norm": 0.4884308874607086,
      "learning_rate": 0.0003754166666666667,
      "loss": 1.1691,
      "step": 1500
    },
    {
      "epoch": 129.16666666666666,
      "grad_norm": 0.6259390115737915,
      "learning_rate": 0.0003545833333333333,
      "loss": 1.1641,
      "step": 1550
    },
    {
      "epoch": 133.33333333333334,
      "grad_norm": 0.48036128282546997,
      "learning_rate": 0.00033375,
      "loss": 1.1547,
      "step": 1600
    },
    {
      "epoch": 133.33333333333334,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1579251289367676,
      "eval_runtime": 0.0295,
      "eval_samples_per_second": 1626.133,
      "eval_steps_per_second": 203.267,
      "step": 1600
    },
    {
      "epoch": 137.5,
      "grad_norm": 0.7468500733375549,
      "learning_rate": 0.0003129166666666667,
      "loss": 1.1624,
      "step": 1650
    },
    {
      "epoch": 141.66666666666666,
      "grad_norm": 0.43708547949790955,
      "learning_rate": 0.0002920833333333333,
      "loss": 1.156,
      "step": 1700
    },
    {
      "epoch": 145.83333333333334,
      "grad_norm": 0.44738927483558655,
      "learning_rate": 0.00027125,
      "loss": 1.1456,
      "step": 1750
    },
    {
      "epoch": 150.0,
      "grad_norm": 0.525580108165741,
      "learning_rate": 0.0002504166666666667,
      "loss": 1.1522,
      "step": 1800
    },
    {
      "epoch": 150.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1470717191696167,
      "eval_runtime": 0.0288,
      "eval_samples_per_second": 1667.149,
      "eval_steps_per_second": 208.394,
      "step": 1800
    },
    {
      "epoch": 154.16666666666666,
      "grad_norm": 0.7807724475860596,
      "learning_rate": 0.00022958333333333335,
      "loss": 1.1483,
      "step": 1850
    },
    {
      "epoch": 158.33333333333334,
      "grad_norm": 0.6235555410385132,
      "learning_rate": 0.00020875,
      "loss": 1.1393,
      "step": 1900
    },
    {
      "epoch": 162.5,
      "grad_norm": 0.5526957511901855,
      "learning_rate": 0.0001879166666666667,
      "loss": 1.1481,
      "step": 1950
    },
    {
      "epoch": 166.66666666666666,
      "grad_norm": 0.5992190837860107,
      "learning_rate": 0.00016708333333333335,
      "loss": 1.1416,
      "step": 2000
    },
    {
      "epoch": 166.66666666666666,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.1403685808181763,
      "eval_runtime": 0.0308,
      "eval_samples_per_second": 1557.833,
      "eval_steps_per_second": 194.729,
      "step": 2000
    },
    {
      "epoch": 170.83333333333334,
      "grad_norm": 0.5168129801750183,
      "learning_rate": 0.00014625,
      "loss": 1.1382,
      "step": 2050
    },
    {
      "epoch": 175.0,
      "grad_norm": 0.7448470592498779,
      "learning_rate": 0.0001254166666666667,
      "loss": 1.1388,
      "step": 2100
    },
    {
      "epoch": 179.16666666666666,
      "grad_norm": 0.570805549621582,
      "learning_rate": 0.00010458333333333333,
      "loss": 1.1361,
      "step": 2150
    },
    {
      "epoch": 183.33333333333334,
      "grad_norm": 0.6156684756278992,
      "learning_rate": 8.375e-05,
      "loss": 1.1392,
      "step": 2200
    },
    {
      "epoch": 183.33333333333334,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.136670470237732,
      "eval_runtime": 0.0361,
      "eval_samples_per_second": 1327.977,
      "eval_steps_per_second": 165.997,
      "step": 2200
    },
    {
      "epoch": 187.5,
      "grad_norm": 0.6622434258460999,
      "learning_rate": 6.291666666666666e-05,
      "loss": 1.1363,
      "step": 2250
    },
    {
      "epoch": 191.66666666666666,
      "grad_norm": 0.8584491610527039,
      "learning_rate": 4.208333333333334e-05,
      "loss": 1.1363,
      "step": 2300
    },
    {
      "epoch": 195.83333333333334,
      "grad_norm": 0.7238142490386963,
      "learning_rate": 2.125e-05,
      "loss": 1.1354,
      "step": 2350
    },
    {
      "epoch": 200.0,
      "grad_norm": 0.6213808059692383,
      "learning_rate": 4.166666666666667e-07,
      "loss": 1.1356,
      "step": 2400
    },
    {
      "epoch": 200.0,
      "eval_accuracy": 0.2222222222222222,
      "eval_loss": 1.135462760925293,
      "eval_runtime": 0.0317,
      "eval_samples_per_second": 1513.142,
      "eval_steps_per_second": 189.143,
      "step": 2400
    }
  ],
  "logging_steps": 50,
  "max_steps": 2400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
